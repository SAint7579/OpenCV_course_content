{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold\n",
    "Lets look at an image first...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('bookpage.jpg')\n",
    "cv2.imshow(\"Book image\",image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasn't easy to read, was it?\n",
    "<br>\n",
    "The reason for that are the dark areas, which are, region with lower pixel values.....<br>\n",
    "<br>\n",
    "<b>but</b>, if we can find the dark pixels and replace it bigger values....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,thresh = cv2.threshold(image,12,255,cv2.THRESH_BINARY) #Thresh is the generated image and ret is confirmation\n",
    "#threshold = 12\n",
    "#maxval = 255\n",
    "#Type of threshold = BINARY\n",
    "cv2.imshow(\"Threshold\",thresh)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That makes it significantly more readable.....but how?\n",
    "<br>\n",
    "We set the threshold as 12, which are the almost black pixels and selected the BINARY threshold. The duo turned every pixel bellow the threshold to 0 and above the threshold to maxval i.e. 255\n",
    "<br>\n",
    "<br>\n",
    "<b>But the color metrices still makes it somewhat difficult to read the text.</b> <br>So maybe we can try a grayscaled image......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "ret,thresh = cv2.threshold(grayscale,12,255,cv2.THRESH_BINARY) #Thresh is the generated image and ret is confirmation\n",
    "#threshold = 12\n",
    "#maxval = 2555\n",
    "cv2.imshow(\"Threshold\",thresh)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that did not work.......................but on a brighter side, it is obvious why...<br><br>\n",
    "Thresholding simply turned the darker area to completely black, making the middel part unreadable.<br>This happened because the lighting in the image is not uniform and therefore, keeping the same threshold value for the entire image is not ideal......\n",
    "<br><br><b>So for the solution,</b>\n",
    "<br>If we could take different threshold values for different areas in the image, it might work!........and the adaptiveThreshold() function does exactly that......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.adaptiveThreshold(grayscale,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,115,1) \n",
    "#maxval = 255\n",
    "#adaptive type = MEAN\n",
    "#Area size = 115\n",
    "#Constant to add = 1\n",
    "cv2.imshow(\"Threshold\",thresh)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A lot better isn't it.....\n",
    "The MEAN function decided the threshold by calculating the mean around the area and thus, the threshold of every grid was different.<br>\n",
    "Another adaptive thresholding method is ADAPTIVE_THRESH_GAUSSIAN_C, which selects the value from a gaussian distribution for the surrounding area......try it out!\n",
    "<br><br>\n",
    "Now, for the other thresholding methods......<br>\n",
    "<img src=\"Notes_image/threshold_types.jpg\">\n",
    "<br><br>\n",
    "There you go......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask\n",
    "<br>\n",
    "<b>What is a mask?</b><br>\n",
    "It is basically an image with only zeros and 255s and can be used to remove the unwanted areas.\n",
    "<br>\n",
    "This can be made using the threshold function on the grayscaled image....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('py.jpg')\n",
    "#Converting the image to grayscale\n",
    "grayscale = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "#Making the mask\n",
    "ret,mask = cv2.threshold(grayscale,220,255,cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Mask\",mask)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The black areas are the one that will be removed and the white ones are kept in the image.<br><br>\n",
    "<b>But....how do we use it?.....</b><br>\n",
    "Using the bitwise AND operation.<br>\n",
    "Now, simple logic: If we AND an image with itself, we will get the same image. Now when we use a mask on the result, it removes the black areas......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_image = cv2.bitwise_and(image,image,mask=mask) #Applying the mask\n",
    "cv2.imshow(\"Masked\",masked_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "#See what it did there......"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters\n",
    "#### Behold......lot of concepts.......\n",
    "The notion is simple, keep only those colors that we want........\n",
    "<br>If the object is<i> Amethyst </i>in color (try finding one....), then remove all the colors except those which are in that range.....Simple?\n",
    "<br> But pulling this off with BGR or RGB images is not that feasible.....why?\n",
    "<br><br>\n",
    "<table><tr>\n",
    "<td><img src=\"Notes_image/Bright.jpg\",height=\"62\" width=\"62\"></td>\n",
    "<td><img src=\"Notes_image/Dark.jpg\",height=\"62\" width=\"62\"></td>\n",
    "</table></tr>\n",
    "Look at these two images.<br>\n",
    "Due to the difference in brightness levels, value of pixels in the red matrix do not remain the same. This makes it difficult to decide the range that is to be kept with the filter.\n",
    "<br><br>\n",
    "<b>The sollution</b>,<br>\n",
    "The HSV color mode. It stands for Hew(or color), Saturation(or intensity) and Value(or brightness) which makes it clear why this one is better. It saperates the lighting details form the color details making the filter work better under different lighting conditions.\n",
    "<img src=\"Notes_image/HSV.png\">\n",
    "<br><b> Now, Refer this graph to decide the color range. X axis the hew and Y axis is the Saturation</b>\n",
    "<br>\n",
    "The range will be 2 lists indicating the upper and lower values of the color. This will be fed to the inRange() function and guess the outcome.......its a mask!\n",
    "<br>\n",
    "But that will be a little noisey. To handle that, we can use some blurring and erosion to get rid of that extra stuff.....\n",
    "<br><br>\n",
    "<b> Now pick up an object and lets being......</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    #Recording the video\n",
    "    _,frame = cap.read()\n",
    "    #Making the hsv image\n",
    "    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    #The color range for that red spool up there.....\n",
    "    lower_red = np.array([0,100,20])\n",
    "    upper_red = np.array([10,255,255])\n",
    "    #Generating the mask\n",
    "    mask = cv2.inRange(hsv,lower_red,upper_red)\n",
    "    #Some erossion and dialation\n",
    "    mask = cv2.erode(mask,None,iterations=2)\n",
    "    \n",
    "    #Removing the removed part\n",
    "    res = cv2.bitwise_and(frame,frame,mask=mask)\n",
    "    \n",
    "    #Eliminating that noisey stuff....\n",
    "    blur = cv2.medianBlur(res,15)\n",
    "\n",
    "    #Lets see what we have got here\n",
    "    cv2.imshow('blur',blur)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  \n",
    "        break\n",
    "        \n",
    "        \n",
    "    #Press q to exit from camera\n",
    "    \n",
    "cap.release()  #Release the camera (necessary)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>And....done</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contours\n",
    "\n",
    "Basically, lines that connect regions with the same color.....\n",
    "<br>\n",
    "Lets try this on a simple image......but a grayscaled one....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('py.jpg')\n",
    "gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "contours,_ = cv2.findContours(gray,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After printing the 'contours' variable, what do think you'll see.<br>\n",
    "Let me spoil it for you, it a collections of arrays. And those arrays have points that are to be connected to make one of the many contours.\n",
    "<br>Lets draw 'em...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.drawContours(image,contours,-1,(255,0,0),3)\n",
    "# The third arg is for the index. -1 means all of them......\n",
    "cv2.imshow(\"Contours\",image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features of contours.....\n",
    "The first one....moments.\n",
    "<br> Basically, 3 points that can be used to tell many things about the image......\n",
    "<br>Example (m01/m00, m10/m00) is the center of that image....see....easy! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lets pick up the largest one \n",
    "cnt = max(contours[1:],key = cv2.contourArea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192670.5"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.contourArea(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Wondering which one it is...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('py.jpg')\n",
    "cv2.drawContours(image,[c],-1,(255,0,0),3)\n",
    "# The third arg is for the index. -1 means all of them......\n",
    "cv2.imshow(\"Contours\",image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>That one......."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
